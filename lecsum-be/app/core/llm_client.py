import os
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from app.core.prompt_templates.quiz_prompt import *
from app.db.quiz_schemas import *

from app.core.prompt_templates.summary_prompt import get_summary_prompt
from app.core.prompt_templates.keyword_prompt import get_keyword_prompt
from app.core.prompt_templates.quiz_prompt import (get_quiz_prompt, get_grading_prompt)
from app.core.prompt_templates.retry_quiz_prompt import get_retry_quiz_prompt
from app.db.quiz_schemas import QuizResponse, GradeResultList
from langchain_core.output_parsers import JsonOutputParser

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ê²€ì¦
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# ê³µí†µ LLM ì¸ìŠ¤í„´ìŠ¤
chatOpenAI = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
)

chatbot_llm = ChatOpenAI(
    temperature=0.7,
    model="gpt-4o-mini",
)

# -----------------------------
# ììœ  í…ìŠ¤íŠ¸ ì¶œë ¥ ì²´ì¸
# -----------------------------
def route_summary_prompt(inputs: dict):
    """
    summary_typeì— ë”°ë¼ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ê¸°í•œë‹¤.
    inputs = {
        "context": str,
        "summary_type": str
    }
    """
    summary_type = inputs.get("summary_type", "lecture")
    return {
        "context": inputs["context"],
        "prompt": get_summary_prompt(summary_type)
    }

summary_chain: Runnable = (
    RunnableLambda(route_summary_prompt)
    | RunnablePassthrough.assign(context=lambda x: x["context"])
    | (lambda x: x["prompt"])
    | chatOpenAI
    | StrOutputParser()
)

keyword_chain: Runnable = (
    get_keyword_prompt()
    | chatOpenAI
    | StrOutputParser()
)

# -----------------------------
# êµ¬ì¡°í™” ì¶œë ¥ ì²´ì¸
# -----------------------------
def build_structured_chain(
    llm: ChatOpenAI,
    prompt,
    output_schema,
) -> Runnable:
    """
    Structured Output(JSON Schema) ê¸°ë°˜ ì²´ì¸ ìƒì„±
    """
    structured_llm = llm.with_structured_output(output_schema)
    return prompt | structured_llm

def build_llm_chain(llm, prompt) -> Runnable:
    chain = prompt | llm | StrOutputParser()
    return chain


quiz_chain: Runnable = build_structured_chain(
    chatOpenAI,
    get_quiz_prompt(),
    QuizGenerationOutput,
)
critic_chain: Runnable = build_llm_chain(
    chatOpenAI,
    get_critic_prompt()
)
refiner_chain: Runnable = build_structured_chain(
    chatOpenAI,
    get_refiner_prompt(), 
    QuizGenerationOutput
)

def route_quiz_generation(info):
    critique = info["critique"]
    
    # ë¹„í‰ ë¡œê·¸ ì¶œë ¥
    print("\n[ğŸ‘€ Critic's Review]\n", critique)
    print("-" * 50)

    if "ìˆ˜ì • ì‚¬í•­ ì—†ìŒ" in critique:
        print("âœ… ê²€ìˆ˜ í†µê³¼: ì´ˆì•ˆì„ ê·¸ëŒ€ë¡œ í™•ì •í•©ë‹ˆë‹¤.")
        return info["initial_quiz"]
    else:
        print("âš ï¸ ìˆ˜ì • í•„ìš”: Refinerë¥¼ ê°€ë™í•©ë‹ˆë‹¤.")
        return refiner_chain

def build_quiz_multichain():
    return (
        # Step 1: ì´ˆì•ˆ ìƒì„±
        RunnablePassthrough.assign(
            initial_quiz=quiz_chain
        )
        # Step 2: ë¹„í‰ ìƒì„± (Criticì—ê²ŒëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ì „ë‹¬)
        .assign(
            critique=RunnablePassthrough.assign(
                initial_quiz=lambda x: x["initial_quiz"].model_dump_json(indent=2)
            ) | critic_chain
        )
        # Step 3: Refinerë¥¼ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ (Pydantic -> JSON String)
        # Refiner í”„ë¡¬í”„íŠ¸ì— ë“¤ì–´ê°ˆ {initial_quiz}ê°€ ë¬¸ìì—´ì´ì–´ì•¼ ì˜ ì¸ì‹í•¨
        .assign(
            initial_quiz=lambda x: x["initial_quiz"].model_dump_json(indent=2) 
            if "ìˆ˜ì • ì‚¬í•­ ì—†ìŒ" not in x["critique"] else x["initial_quiz"]
        )
        # Step 4: ë¼ìš°íŒ… (ìˆ˜ì • í•„ìš”í•˜ë©´ Refiner, ì•„ë‹ˆë©´ Pass)
        | RunnableLambda(route_quiz_generation)
    )

# MultiChain
quiz_critic_refiner_chain = build_quiz_multichain()

# ì±„ì  - í•´ì„¤ ë³´ê°• Chain
grade_chain: Runnable = build_structured_chain(
    chatOpenAI,
    get_grading_prompt(),
    GradeResultList,
)
enrich_chain: Runnable = build_llm_chain(
    ChatOpenAI(model="gpt-4o-mini", temperature=0.7),
    get_enrichment_prompt()
)

# ì˜¤ë‹µ ì¬ì‹œí—˜ ì²´ì¸
retry_quiz_chain: Runnable = build_structured_chain(
    chatOpenAI,
    get_retry_quiz_prompt(),
    QuizResponse, # í€´ì¦ˆ ìƒì„±ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œí—˜ ìƒì„±
)

top_sentence_chain: Runnable = (
    ChatPromptTemplate.from_template("""
    ë‹¤ìŒ ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¬¸ì¥ {k}ê°œë¥¼ ì¶”ì¶œí•˜ë¼.
    JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ë¼.

    {context}
    """)
    | chatOpenAI
    | JsonOutputParser()
)
